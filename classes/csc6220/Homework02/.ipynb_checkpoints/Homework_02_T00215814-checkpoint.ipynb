{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSC 6220 Homework 2\n",
    "#### Rob Gillen, T00215814"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup some things for subsequent computations\n",
    "%matplotlib inline\n",
    "\n",
    "import math\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6.6 (20pts)\n",
    "\n",
    "__A database has five transactions. Let $minSup=60\\%$ and $minConf = 80\\%$__\n",
    "\n",
    "|TID|items_bought|\n",
    "|---|------------|\n",
    "|T100 |{M, O, N, K, E, Y}|\n",
    "|T200 |{D, O, N, K, E, Y}|\n",
    "|T300 |{M, A, K, E}|\n",
    "|T400 |{M, U, C, K, Y}|\n",
    "|T500 |{C, O, O, K, I, E}|\n",
    "\n",
    "\n",
    "\n",
    "__(a) Find all frequent itemsets using Apriori and FP-Growth, respectively. Compare the efficiency of the two mining processes.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b) List all the _strong_ association rules (with support $s$ and confidence $c$) matching the following metarule, where $X$ is a variable representing customers, and $item_i$ deones variables representing items (e.g. \"A\", \"B\"):__\n",
    "\n",
    "$$\\forall x \\in transaction, buys(X, item_1) \\wedge buys(X, item_2) \\implies buys(X, item_3) [s, c]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 6.9 (15pts)\n",
    "\n",
    "__Suppose that a large store has a transactional database that is _distributed_ among four locations. Transactions in each component database have the same format, namely $T_j:{i_1,...,i_m}$, where $T_j$ is a transaction identifier, and $i_k(1 \\leq k \\leq m)$ is the identifier of an item purchased in the transaction. Propose an efficient algorithm to mine global association rules. You may present your algorithm in the form of an outline. Your algorithm should not require shipping all the data to one site and shoud not cause excessive network communication overhead.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7.7 (not d) (15pts)\n",
    "\n",
    "__The price of each item in a store is non-negative. The sotre manager is only interested in rules of certain forms, using the constraints given in (a)-(b). For each of teh following cases, identify the kinds of _constraints_ they represent and briefly discuss how to mine such association rules using _constraint-based pattern mining._ __\n",
    "\n",
    "\n",
    "| | Rule Constraint | Antimonotonic | Monotonic | Succinct |\n",
    "|--|--|--|--|--|\n",
    "|(a)| $v \\in S$ | no | yes | yes |\n",
    "|(b)| $S \\subseteq V $ | yes | no | yes |\n",
    "\n",
    "__(a) Containing at least one Blu-ray DVD movie:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b) Containing items with a sum of the prices that is less than $150.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c) Containing one free item and other items with a sum of the prices that is at least $200.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.2 (20pts)\n",
    "\n",
    "__Why is _tree pruning_ useful in decision tree induction? What is a drawback of using a separate set of tuples to evaluate pruning?__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.12 (not the ROC curve) (18pts)\n",
    "\n",
    "__The data tuples of Figure 8.25 are sorted by decreasing probability value, as returned by a classifier. For each tuple, compute the values for the number of true positives (TP), false positives (FP), true negatives (TN), and false negatives (FN). Compute the true positive rate (TPR) and false positive rate (FPR). Plot the ROC curve for the data.__\n",
    "\n",
    "| Tuple # | Class | Probability |\n",
    "|----:|:--:|----:|\n",
    "| 1  | P | 0.95 |\n",
    "| 2  | N | 0.85 |\n",
    "| 3  | P | 0.78 |\n",
    "| 4  | P | 0.66 |\n",
    "| 5  | N | 0.60 |\n",
    "| 6  | P | 0.55 |\n",
    "| 7  | N | 0.53 |\n",
    "| 8  | N | 0.52 |\n",
    "| 9  | N | 0.51 |\n",
    "| 10 | P | 0.40 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8.15 (12pts)\n",
    "\n",
    "__What is _boosting_? State why it may improve teh accuracy of decision tree induction.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
