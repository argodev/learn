---
title: Single Chip Heterogeneity - A Brief Survey
author: Rob Gillen
header-includes:
    - \usepackage{fancyhdr}
    - \pagestyle{fancy}
    - \fancyhead[RO,RE]{Single Chip Heterogeneity - A Brief Survey}
    - \fancyhead[LO,LE]{Rob Gillen, T00215814}
    - \usepackage{tikz}
    - \usetikzlibrary{calc,shapes.multipart,chains,arrows}
fontsize: 12pt
---

## Introduction
A review of the past 40 years of computing will show a constant flux in the amount of processor heterogeneity used in generally available systems. Discrete components yielded to solid-state devices which in turn saw the emergence of math co-processors, graphics co-processors, network co-processors and many others. In the realm of parallel or high-performance computing, a similar trend has emerged. In recent years we have witnessed the broad transition from clusters consisting of many identical processors to those having unique processor cards such as GPUs, ASICs, or FPGAs. Even commercial cloud providers have added various heterogeneous processing nodes to their existing by-the-hour service offerings.

Consistent with other trends in industry, advances in large-scale platforms often transition to small-scale, discrete platforms. Heterogeneous computing (HC) is no different. Nearly every motherboard sold in the past 10 years represents a level of heterogeneous computing simply by hosting not only a general processing unit (GPU/CPU), but also embedded video display chips, network communication chips, audio chips, and others. In more recent years, these advances have been pushed from the node level to the board level, and now to the chip level. Various manufacturers are seeing the benefits of co-locating disparate processor architectures on the same piece of silicon. This paper provides a brief review of four papers that deal both with heterogeneous computing in general as well as single-chip heterogeneity in particular.


## Heterogeneous Computing: Here To Stay
Published in 2016, this is a position paper by Mohamed Zahran explaining his views on the HC landscape. Zahran broadly introduces the topic and then discusses a number of different processor types including central processing units (CPU), graphics processing units (GPU), field-programmable gate arrays (FPGA), automata processors (AP), neuromorphic processors, application-specific integrated circuits (ASIC) and digital signal processors (DSP). He discusses the interplay between the targeted roles for each of these processor types and then discusses both the benefits of this interplay as well as a number of outstanding issues preventing wide-spread adoption. As is evident from the title, he argues that the issues must and will be addressed and HC is with us for the long term.

Of particular note was the commentary on some of the existing issues. The rise of single-chip multi-core processors in recent years has highlighted the fact that many software developers (and their codes) are poorly-equipped to properly leverage moderately-distributed computing. The popularity of the re-purposing of high-performing graphics cards for general computing has shown not only the general interest but that the gap in capable programmers broadens quickly when moving from CPU to CPU/GPU combinations. The situation is exacerbated as additional disparate processors are added to the system. Locating a single developer (or even a team of them) that can effectively utilize a system with this level of heterogeneity (not only able to program each of the processors, but proper orchestration across them) is a task that simultaneously requires a high-level of specialization as well as a breadth of knowledge encompassing the various processor types involved. The Page Three initiative from DARPA's Electronics Resurgence Initiative lends further credence to this problem as they aim to develop tools and methods to orchestrate best-of-breed ``blocks'' of computational logic to program/use dynamically disparate heterogeneous chips. The author's assertion that HC is here to stay appears to be supported, but so do the problems that lay ahead for effective use of such systems.


## Elastic Computing: A Framework for Transparent, Portable, and Adaptive Multi-core Heterogenous Computing
Although the name of this paper - Elastic Computing (EC) - was an unfortunate choice given the recent appropriation of the term by the cloud computing movement, it does hint at the dynamicism of the platform that the authors' envisioned. This platform is best summarized by a descriptive sentence on the second page that says ``Elastic computing is largely intended to enable mainstream application designers, who often lack the skills required for programming specialized devices, to take advantage of such devices with minimal effort''. To accomplish this goal they propose a system that consists of three building blocks: Elastic Functions, an Implementation Planning tool, and the Elastic Computing Runtime environment.

The Elastic Functions are pre-packaged version of core algorithms (e.g. merge sort, bubble sort, etc.) that are implemented in many different ways (single-threaded CPU, multi-threaded CPU, GPU, FPGA, etc.). A developer who wishes to utilize one of these functions would develop to a standard interface that allows him to not only call the function but also to describe a little about what is being called (e.g. random sort vs. reversed, the scale of data, etc.). The EC runtime then evaluates which version (implementation) of the elastic function (EF) is best suited to provide the needed results and calls it appropriately. This runtime decision is dependent on the Implementation Planning Tool which develops a performance profile of each EF given the current system on which it is installed. This tool is run at installation as well as any time a performance-significant change is made to the system. This profile data allows the runtime to know that the current host has an FPGA and an 8-core CPU and allows it to choose the right implementation given the current circumstances.

While there are many aspects of this approach one might find interesting, the fact that the system allows for context to be provided with each call is one of the more significant. The authors both acknowledge and design for the fact that the ``right'' algorithm implementation choice is not simply determined by what hardware is available in the system, but might include a number of other factors such as the size of the input data, the power state of the host (running on battery, plugged in, etc.), the bandwidth between the various processors, etc.

This paper, while published six years prior, is well positioned to address some of the topics identified by Zahran's paper. In reality, however, the fact that Zahran wrote about the HC programming challenges tends to suggest that this work was not (or has not yet been) widely adopted or successful.


## A Survey on hardware-aware and heterogenous computing on multicore processors and accelerators
This survey paper, published in 2011 by authors from the Karlsruhe Institute of Technology (Germany) provides a broad-stroke overview of the state of practice for heterogeneous systems and makes a case for hardware-aware computing. While their focus is specifically high-performance numerical simulation, the observations they make are applicable to the broader computing community. After introducing the general landscape, they spend a significant portion of the paper characterizing the heterogeneous computing domain - describing in detail a number of different processor types, designs, and even discuss communication layout issues. They then describe the programming tools available to parallel and heterogeneous processor developers and highlight how they fall short. Finally, they make their case for hardware-aware programming, going so far as to say ``For a profitable deployment of modern concepts and technologies, a deep insight into both hardware and application characteristics is required''.

One point the authors make that runs contrary to common intuition is one of their proposed solutions for addressing the ``memory wall''. They (like many others) discuss the impact that the slow memory access times have on keeping other processors busy, and stress that pushing for more efficient and faster processors (of various types) may do little other than to highlight the memory issues and result in little more than new and fancy processors sitting generally idle while waiting for data to arrive. One of their proposed solutions, however, was to re-think/re-work algorithms such that they limit their communication as much as possible, *even at the expense of redundant computation*. The premise being that this extra (*wasted*) computation serves a broader purpose in allowing lower overall runtimes due to reduced wasted cycles from latency issues.

While the authors' review of the current state of practice was (and to a large degree, still is) accurate, we struggle to agree with the conclusion - promoting the notion that application developers should (yea, *must*) possess an intimate knowledge of the hardware to effectively utilize it. We would counter that, in our opinion, while current technologies support this claim, that is not the way it should be. The computer science community, while pushing for ever greater performance and utilizing multiple and varied processor architectures to do so, must also focus on developing compilers, optimizers, and other tools to support broad portability and to allow programmers to obtain reasonable (although possibly not optimal) performance from these systems without requiring that they redesign their algorithms for each one.



## Single-Chip Heterogenous Computing: Does the Future Include Custom Logic, FPGAs, and GPGPUs?
In contrast to the other papers reviewed here, this paper is not a survey-style paper but rather attempts to make the case for single-chip heterogeneity based on a mathematical model. The authors begin, like most of the others, by building the case for heterogeneity and explaining why the current approaches are failing. Among other reasons, these authors highlight the fact that power consumption may be one of the driving constraints and is a significant driver for a new approach. They refer to any processor other than a CPU as unconventional cores (U-cores). They limit their analysis and modeling of U-cores on custom logic (ASICs), FPGAs and GPUs.

Due to the fact that, at the time the paper was written, single-chip heterogeneity was not available, they collected data from discrete components and then applied them to their model (based on Hill and Marty) to compare computation, power, bandwidth, and other variables. Based on the assumptions and models they devised, they conclude that single-chip heterogeneity should be included in the future of computing. They temper their recommendation by clarifying that (much like many other scenarios), sufficient parallelism must exist in the original codes for them to benefit from the use of U-cores due to the overhead cost of transferring data between the cores. They further stress that ASICs provide the best performance per watt, but come with the highest non-recoverable engineering cost (NRE). Their results show that FPGAs and GPUs can be a valid option, sometimes exhibiting improved performance/power optimization compared to CPUs while not as good as ASICs.

It is worth noting that they describe in Figure 1c, a hypothetical chip that contains a CPU in a sea of U-cores (on the same silicon). Now, seven years later, that model is not hypothetical and is embodied in the Xilinx Zynq Ultrascale+ chip which houses two ARM Coretext A53 application processors, two ARM Coretext R5 real-time processors, and a large FPGA fabric all on the same piece of silicon and connected with high-speed interconnects.


## Conclusion
There is a noticeable cohesion between the three papers published in 2010-11 - the views of the authors as to the state of the industry, the motivations towards heterogeneous computing and the challenges that exist. One provided a survey, another presented a computational model justifying putting heterogeneous cores on the same chip, and the third presented a computational model aimed at making such systems useable. It is interesting, however, to compare these papers with the 2016 survey paper. To a large degree, it appears that the state of practice has not significantly improved in the intervening six years. The justification for heterogeneous computing is just as strong now as it was in 2010. There has been progress in chip design leading to both a proliferation of heterogeneous processors used for various computing applications (FPGAs, GPUs, ASICs, DSPs, Neuromorphic) as well as single-chip heterogeneity (Xilinx Zynq, Altera Cyclone). The ability for programmers to efficiently utilize these varied processors still remains a significant issue. Many vendors are working to address this challenge - NVidia CUDA, Xilinx HLS, OpenCL, even Matlab. Each of these tools attempts to ease the developers use of these complex processors - and to some degree they are successful, yet attaining both developer productivity and full processor utilization remains an elusive goal.


## References
- Eric S. Chung, Peter A. Milder, James C. Hoe, and Ken Mai. 2010. Single-Chip Heterogeneous Computing: Does the Future Include Custom Logic, FPGAs, and GPGPUs?. In Proceedings of the 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO '43). IEEE Computer Society, Washington, DC, USA, 225-236. DOI=http://dx.doi.org/10.1109/MICRO.2010.36

- Rainer Buchty, Vincent Heuveline, Wolfgang Karl, and Jan-Philipp Weiss. 2012. A survey on hardware-aware and heterogeneous computing on multicore processors and accelerators. Concurr. Comput. : Pract. Exper. 24, 7 (May 2012), 663-675. DOI=http://dx.doi.org/10.1002/cpe.1904

- John Robert Wernsing and Greg Stitt. 2010. Elastic computing: a framework for transparent, portable, and adaptive multi-core heterogeneous computing. In Proceedings of the ACM SIGPLAN/SIGBED 2010 conference on Languages, compilers, and tools for embedded systems (LCTES '10). ACM, New York, NY, USA, 115-124. DOI=http://dx.doi.org/10.1145/1755888.1755906

- Mohamed Zahran. 2017. Heterogeneous computing: here to stay. Commun. ACM 60, 3 (February 2017), 42-45. DOI: https://doi.org/10.1145/3024918
